{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Html extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unstructured.partition.auto import partition\n",
    "\n",
    "# Read HTML file while preserving line numbers\n",
    "with open(\"ht-eb-fa-1.html\", \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# Extract elements using unstructured.partition.auto\n",
    "elements = partition(filename=\"ht-eb-fa-1.html\", include_metadata=True)\n",
    "\n",
    "# Store extracted text with line numbers\n",
    "line_text_map = []\n",
    "\n",
    "# Map extracted text to original line numbers\n",
    "for element in elements:\n",
    "    text = element.text.strip()\n",
    "    if text:  # Ignore empty elements\n",
    "        for i, line in enumerate(lines, start=1):\n",
    "            if text in line:\n",
    "                line_text_map.append((i, text))\n",
    "                break  # Stop at the first occurrence\n",
    "\n",
    "# Sort by line number in ascending order\n",
    "line_text_map.sort()\n",
    "\n",
    "# Print the results\n",
    "for line_num, text in line_text_map:\n",
    "    print(f\"Line {line_num}: {text}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero-shot Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "client = OpenAI(base_url=\"\", api_key=\"\")\n",
    "html_data = pd.read_excel(\"html_data.xlsx\")\n",
    "html_inputs = html_data['html'].to_list()\n",
    "\n",
    "# Define category-specific attribute sets\n",
    "category_attributes = {\n",
    "    \"fashion\": [\"Object\", \"Brand\", \"Color\", \"Size\", \"Material\", \"Department\", \"Style\", \"Price\"],\n",
    "    \"electronics\": [\"Object\", \"Brand\", \"Color\", \"Size\", \"Material\", \"Model\", \"Power Mode\", \"Price\"],\n",
    "    \"beauty\": [\"Object\", \"Brand\", \"Volume\", \"Material\", \"Skin/Hair Type\", \"Benefits\", \"Price\"]\n",
    "}\n",
    "\n",
    "\n",
    "# Helper function to process each category\n",
    "def process_category(category, html_content):\n",
    "    attributes = category_attributes.get(category, [])\n",
    "    if not attributes:\n",
    "        return \"No valid attributes for this category.\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"meta-llama/llama-3.2-11b-vision-instruct:free\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a world-class algorithm for extracting provided product attributes from html in structured formats, strictly exclude any unrelated information.\"}\n",
    "        ] + [\n",
    "            {\"role\": \"user\", \"content\": f\"Extract the product attribute values from the html in a JSON format. Valid attributes are {', '.join(attributes)}. If an attribute is not present in the html, the attribute value is supposed to be ‘n/a’:\\n{html_content}\\n\\nResponse:\"}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    if response.choices and response.choices[0].message and response.choices[0].message.content:\n",
    "        return response.choices[0].message.content\n",
    "    elif hasattr(response, \"error\"):\n",
    "        return f\"API Error: {response.error}\"\n",
    "    else:\n",
    "        return \"No content returned from the API.\"\n",
    "\n",
    "# Main loop for processing the HTML inputs\n",
    "for i, row in html_data.iterrows():\n",
    "    with open(row[\"html\"], \"r\", encoding=\"utf-8\") as file:\n",
    "        html_content = file.read()\n",
    "\n",
    "    # Process based on category\n",
    "    if row[\"category\"] in category_attributes:\n",
    "        result = process_category(row[\"category\"], html_content)\n",
    "        html_data.at[i, 'llama_zeroshot'] = result\n",
    "        print(result)\n",
    "    else:\n",
    "        html_data.at[i, 'llama_zeroshot'] = \"No valid category.\"\n",
    "    time.sleep(20)\n",
    "\n",
    "print(html_data[\"llama_zeroshot\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Mistral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "client = OpenAI(base_url=\"\", api_key=\"\")\n",
    "html_data = pd.read_excel(\"html_data.xlsx\")\n",
    "html_inputs = html_data['html'].to_list()\n",
    "\n",
    "# Define category-specific attribute sets\n",
    "category_attributes = {\n",
    "    \"fashion\": [\"Object\", \"Brand\", \"Color\", \"Size\", \"Material\", \"Department\", \"Style\", \"Price\"],\n",
    "    \"electronics\": [\"Object\", \"Brand\", \"Color\", \"Size\", \"Material\", \"Model\", \"Power Mode\", \"Price\"],\n",
    "    \"beauty\": [\"Object\", \"Brand\", \"Volume\", \"Material\", \"Skin/Hair Type\", \"Benefits\", \"Price\"]\n",
    "}\n",
    "\n",
    "# Helper function to process each category\n",
    "def process_category(category, html_content):\n",
    "    attributes = category_attributes.get(category, [])\n",
    "    if not attributes:\n",
    "        return \"No valid attributes for this category.\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"mistralai/mistral-small-3.1-24b-instruct:free\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a world-class algorithm for extracting provided product attributes from html in structured formats, strictly exclude any unrelated information.\"}\n",
    "        ] + [\n",
    "            {\"role\": \"user\", \"content\": f\"Extract the product attribute values from the html in a JSON format. Valid attributes are {', '.join(attributes)}. If an attribute is not present in the html, the attribute value is supposed to be ‘n/a’:\\n{html_content}\\n\\nResponse:\"}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    if response.choices and response.choices[0].message and response.choices[0].message.content:\n",
    "        return response.choices[0].message.content\n",
    "    elif hasattr(response, \"error\"):\n",
    "        return f\"API Error: {response.error}\"\n",
    "    else:\n",
    "        return \"No content returned from the API.\"\n",
    "\n",
    "# Main loop for processing the HTML inputs\n",
    "for i, row in html_data.iterrows():\n",
    "    with open(row[\"html\"], \"r\", encoding=\"utf-8\") as file:\n",
    "        html_content = file.read()\n",
    "\n",
    "    # Process based on category\n",
    "    if row[\"category\"] in category_attributes:\n",
    "        result = process_category(row[\"category\"], html_content)\n",
    "        html_data.at[i, 'mistral_zeroshot'] = result\n",
    "        print(result)\n",
    "    else:\n",
    "        html_data.at[i, 'mistral_zeroshot'] = \"No valid category.\"\n",
    "    time.sleep(20)\n",
    "\n",
    "print(html_data[\"mistral_zeroshot\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Qwen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "client = OpenAI(base_url=\"\", api_key=\"\")\n",
    "html_data = pd.read_excel(\"html_data.xlsx\")\n",
    "html_inputs = html_data['html'].to_list()\n",
    "\n",
    "# Define category-specific attribute sets\n",
    "category_attributes = {\n",
    "    \"fashion\": [\"Object\", \"Brand\", \"Color\", \"Size\", \"Material\", \"Department\", \"Style\", \"Price\"],\n",
    "    \"electronics\": [\"Object\", \"Brand\", \"Color\", \"Size\", \"Material\", \"Model\", \"Power Mode\", \"Price\"],\n",
    "    \"beauty\": [\"Object\", \"Brand\", \"Volume\", \"Material\", \"Skin/Hair Type\", \"Benefits\", \"Price\"]\n",
    "}\n",
    "\n",
    "# Helper function to process each category\n",
    "def process_category(category, html_content):\n",
    "    attributes = category_attributes.get(category, [])\n",
    "    if not attributes:\n",
    "        return \"No valid attributes for this category.\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"qwen/qwen2.5-vl-72b-instruct:free\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a world-class algorithm for extracting provided product attributes from html in structured formats, strictly exclude any unrelated information.\"}\n",
    "        ] + [\n",
    "            {\"role\": \"user\", \"content\": f\"Extract the product attribute values from the html in a JSON format. Valid attributes are {', '.join(attributes)}. If an attribute is not present in the html, the attribute value is supposed to be ‘n/a’:\\n{html_content}\\n\\nResponse:\"}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    if response.choices and response.choices[0].message and response.choices[0].message.content:\n",
    "        return response.choices[0].message.content\n",
    "    elif hasattr(response, \"error\"):\n",
    "        return f\"API Error: {response.error}\"\n",
    "    else:\n",
    "        return \"No content returned from the API.\"\n",
    "\n",
    "# Main loop for processing the HTML inputs\n",
    "for i, row in html_data.iterrows():\n",
    "    with open(row[\"html\"], \"r\", encoding=\"utf-8\") as file:\n",
    "        html_content = file.read()\n",
    "\n",
    "    # Process based on category\n",
    "    if row[\"category\"] in category_attributes:\n",
    "        result = process_category(row[\"category\"], html_content)\n",
    "        html_data.at[i, 'qwen_zeroshot'] = result\n",
    "        print(result)\n",
    "    else:\n",
    "        html_data.at[i, 'qwen_zeroshot'] = \"No valid category.\"\n",
    "    time.sleep(20)\n",
    "\n",
    "print(html_data[\"qwen_zeroshot\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_data.to_excel(\"html_data.xlsx\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Few-shot Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few-shot by platform & category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "import json\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI(base_url=\"\", api_key=\"\")\n",
    "\n",
    "# Load the HTML data from the Excel file\n",
    "html_data = pd.read_excel(\"html_data.xlsx\")\n",
    "\n",
    "# Filter the test data from the dataset\n",
    "test_data = html_data[html_data['set'] == 'test']\n",
    "\n",
    "# Define category-specific attribute sets\n",
    "category_attributes = {\n",
    "    \"fashion\": [\"Object\", \"Brand\", \"Color\", \"Size\", \"Material\", \"Department\", \"Style\", \"Price\"],\n",
    "    \"electronics\": [\"Object\", \"Brand\", \"Color\", \"Size\", \"Material\", \"Model\", \"Power Mode\", \"Price\"],\n",
    "    \"beauty\": [\"Object\", \"Brand\", \"Volume\", \"Material\", \"Skin/Hair Type\", \"Benefits\", \"Price\"]\n",
    "}\n",
    "\n",
    "platforms = [\"amazon\", \"ebay\", \"temu\"]\n",
    "\n",
    "# Helper function to generate few-shot examples based on the \"train\" set data\n",
    "def generate_few_shot_examples(category, platform, data):\n",
    "    examples = []\n",
    "    \n",
    "    # Filter data based on category and platform\n",
    "    filtered_data = data[(data['category'] == category) & (data['platform'] == platform) & (data['set'] == 'train')]\n",
    "    \n",
    "    for _, row in filtered_data.iterrows():\n",
    "        html_file_path = row['html']  # Path to the HTML file\n",
    "        \n",
    "        # Read the HTML content from the file\n",
    "        try:\n",
    "            with open(html_file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                html_content = file.read()\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File not found: {html_file_path}\")\n",
    "            html_content = \"\"\n",
    "        \n",
    "        reference_output = row['reference_output']  # Correct answer (reference output)\n",
    "        \n",
    "        # Construct the few-shot example\n",
    "        example = {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are an algorithm that extracts product attributes from HTML in a structured format. Only extract the specified attributes and exclude unrelated information.\"\n",
    "        }\n",
    "        \n",
    "        user_content = f\"Extract product attributes from the HTML. Valid attributes are {', '.join(category_attributes.get(category, []))}. If an attribute is not present in the HTML, the value should be 'n/a'.\\n\\nHTML content:\\n{html_content}\\n\\nReference Output:\\n{reference_output}\"\n",
    "        assistant_content = reference_output  # The correct response to match the attributes\n",
    "        \n",
    "        examples.append({\"role\": \"user\", \"content\": user_content})\n",
    "        examples.append({\"role\": \"assistant\", \"content\": assistant_content})\n",
    "    \n",
    "    return examples\n",
    "\n",
    "# Helper function to process each category/platform with few-shot examples\n",
    "def process_category_platform(category, platform, html_content):\n",
    "    examples = generate_few_shot_examples(category, platform, html_data)\n",
    "    \n",
    "    if not examples:\n",
    "        return \"No valid few-shot examples for this category/platform.\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"meta-llama/llama-3.2-11b-vision-instruct:free\",  # Specify the model you want to use\n",
    "        messages=examples + [\n",
    "            {\"role\": \"user\", \"content\": f\"Extract the product attribute values from the HTML in a JSON format. Valid attributes are {', '.join(category_attributes[category])}:\\n{html_content}\\n\\nResponse:\"}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    if response.choices and response.choices[0].message and response.choices[0].message.content:\n",
    "        return response.choices[0].message.content\n",
    "    elif hasattr(response, \"error\"):\n",
    "        return f\"API Error: {response.error}\"\n",
    "    else:\n",
    "        return \"No content returned from the API.\"\n",
    "\n",
    "# Main loop for processing the test set HTML inputs\n",
    "for i, row in test_data.iterrows():\n",
    "    html_file_path = row[\"html\"]  # Get the path to the HTML file\n",
    "\n",
    "    # Read the HTML content from the file\n",
    "    try:\n",
    "        with open(html_file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            html_content = file.read()\n",
    "\n",
    "        # Process based on category and platform\n",
    "        if row[\"category\"] in category_attributes and row[\"platform\"] in platforms:\n",
    "            result = process_category_platform(row[\"category\"], row[\"platform\"], html_content)\n",
    "            test_data.at[i, 'llama_fewshot'] = result  # Write result to 'llama_fewshot' column\n",
    "            print(result)\n",
    "        else:\n",
    "            test_data.at[i, 'llama_fewshot'] = \"No valid category.\"\n",
    "    except FileNotFoundError:\n",
    "        test_data.at[i, 'llama_fewshot'] = f\"HTML file not found: {html_file_path}\"\n",
    "        print(f\"HTML file not found: {html_file_path}\")\n",
    "\n",
    "# Write the results back to the original dataframe\n",
    "html_data.update(test_data[['html', 'llama_fewshot']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Mistral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "import json\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI(base_url=\"\", api_key=\"\")\n",
    "\n",
    "# Load the HTML data from the Excel file\n",
    "html_data = pd.read_excel(\"html_data.xlsx\")\n",
    "\n",
    "# Filter the test data from the dataset\n",
    "test_data = html_data[html_data['set'] == 'test']\n",
    "\n",
    "# Define category-specific attribute sets\n",
    "category_attributes = {\n",
    "    \"fashion\": [\"Object\", \"Brand\", \"Color\", \"Size\", \"Material\", \"Department\", \"Style\", \"Price\"],\n",
    "    \"electronics\": [\"Object\", \"Brand\", \"Color\", \"Size\", \"Material\", \"Model\", \"Power Mode\", \"Price\"],\n",
    "    \"beauty\": [\"Object\", \"Brand\", \"Volume\", \"Material\", \"Skin/Hair Type\", \"Benefits\", \"Price\"]\n",
    "}\n",
    "\n",
    "platforms = [\"amazon\", \"ebay\", \"temu\"]\n",
    "\n",
    "# Helper function to generate few-shot examples based on the \"train\" set data\n",
    "def generate_few_shot_examples(category, platform, data):\n",
    "    examples = []\n",
    "    \n",
    "    # Filter data based on category and platform\n",
    "    filtered_data = data[(data['category'] == category) & (data['platform'] == platform) & (data['set'] == 'train')]\n",
    "    \n",
    "    for _, row in filtered_data.iterrows():\n",
    "        html_file_path = row['html']  # Path to the HTML file\n",
    "        \n",
    "        # Read the HTML content from the file\n",
    "        try:\n",
    "            with open(html_file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                html_content = file.read()\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File not found: {html_file_path}\")\n",
    "            html_content = \"\"\n",
    "        \n",
    "        reference_output = row['reference_output']  # Correct answer (reference output)\n",
    "        \n",
    "        # Construct the few-shot example\n",
    "        example = {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are an algorithm that extracts product attributes from HTML in a structured format. Only extract the specified attributes and exclude unrelated information.\"\n",
    "        }\n",
    "        \n",
    "        user_content = f\"Extract product attributes from the HTML. Valid attributes are {', '.join(category_attributes.get(category, []))}. If an attribute is not present in the HTML, the value should be 'n/a'.\\n\\nHTML content:\\n{html_content}\\n\\nReference Output:\\n{reference_output}\"\n",
    "        assistant_content = reference_output  # The correct response to match the attributes\n",
    "        \n",
    "        examples.append({\"role\": \"user\", \"content\": user_content})\n",
    "        examples.append({\"role\": \"assistant\", \"content\": assistant_content})\n",
    "    \n",
    "    return examples\n",
    "\n",
    "# Helper function to process each category/platform with few-shot examples\n",
    "def process_category_platform(category, platform, html_content):\n",
    "    examples = generate_few_shot_examples(category, platform, html_data)\n",
    "    \n",
    "    if not examples:\n",
    "        return \"No valid few-shot examples for this category/platform.\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"mistralai/mistral-small-3.1-24b-instruct:free\",  # Specify the model you want to use\n",
    "        messages=examples + [\n",
    "            {\"role\": \"user\", \"content\": f\"Extract the product attribute values from the HTML in a JSON format. Valid attributes are {', '.join(category_attributes[category])}:\\n{html_content}\\n\\nResponse:\"}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    if response.choices and response.choices[0].message and response.choices[0].message.content:\n",
    "        return response.choices[0].message.content\n",
    "    elif hasattr(response, \"error\"):\n",
    "        return f\"API Error: {response.error}\"\n",
    "    else:\n",
    "        return \"No content returned from the API.\"\n",
    "\n",
    "# Main loop for processing the test set HTML inputs\n",
    "for i, row in test_data.iterrows():\n",
    "    html_file_path = row[\"html\"]  # Get the path to the HTML file\n",
    "\n",
    "    # Read the HTML content from the file\n",
    "    try:\n",
    "        with open(html_file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            html_content = file.read()\n",
    "\n",
    "        # Process based on category and platform\n",
    "        if row[\"category\"] in category_attributes and row[\"platform\"] in platforms:\n",
    "            result = process_category_platform(row[\"category\"], row[\"platform\"], html_content)\n",
    "            test_data.at[i, 'mistral_fewshot'] = result  # Write result to 'mistral_fewshot' column\n",
    "            print(result)\n",
    "        else:\n",
    "            test_data.at[i, 'mistral_fewshot'] = \"No valid category.\"\n",
    "    except FileNotFoundError:\n",
    "        test_data.at[i, 'mistral_fewshot'] = f\"HTML file not found: {html_file_path}\"\n",
    "        print(f\"HTML file not found: {html_file_path}\")\n",
    "\n",
    "# Write the results back to the original dataframe\n",
    "html_data.update(test_data[['html', 'mistral_fewshot']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Qwen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "import json\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI(base_url=\"\", api_key=\"\")\n",
    "\n",
    "# Load the HTML data from the Excel file\n",
    "html_data = pd.read_excel(\"html_data.xlsx\")\n",
    "\n",
    "# Filter the test data from the dataset\n",
    "test_data = html_data[html_data['set'] == 'test']\n",
    "\n",
    "# Define category-specific attribute sets\n",
    "category_attributes = {\n",
    "    \"fashion\": [\"Object\", \"Brand\", \"Color\", \"Size\", \"Material\", \"Department\", \"Style\", \"Price\"],\n",
    "    \"electronics\": [\"Object\", \"Brand\", \"Color\", \"Size\", \"Material\", \"Model\", \"Power Mode\", \"Price\"],\n",
    "    \"beauty\": [\"Object\", \"Brand\", \"Volume\", \"Material\", \"Skin/Hair Type\", \"Benefits\", \"Price\"]\n",
    "}\n",
    "\n",
    "platforms = [\"amazon\", \"ebay\", \"temu\"]\n",
    "\n",
    "# Helper function to generate few-shot examples based on the \"train\" set data\n",
    "def generate_few_shot_examples(category, platform, data):\n",
    "    examples = []\n",
    "    \n",
    "    # Filter data based on category and platform\n",
    "    filtered_data = data[(data['category'] == category) & (data['platform'] == platform) & (data['set'] == 'train')]\n",
    "    \n",
    "    for _, row in filtered_data.iterrows():\n",
    "        html_file_path = row['html']  # Path to the HTML file\n",
    "        \n",
    "        # Read the HTML content from the file\n",
    "        try:\n",
    "            with open(html_file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                html_content = file.read()\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File not found: {html_file_path}\")\n",
    "            html_content = \"\"\n",
    "        \n",
    "        reference_output = row['reference_output']  # Correct answer (reference output)\n",
    "        \n",
    "        # Construct the few-shot example\n",
    "        example = {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are an algorithm that extracts product attributes from HTML in a structured format. Only extract the specified attributes and exclude unrelated information.\"\n",
    "        }\n",
    "        \n",
    "        user_content = f\"Extract product attributes from the HTML. Valid attributes are {', '.join(category_attributes.get(category, []))}. If an attribute is not present in the HTML, the value should be 'n/a'.\\n\\nHTML content:\\n{html_content}\\n\\nReference Output:\\n{reference_output}\"\n",
    "        assistant_content = reference_output  # The correct response to match the attributes\n",
    "        \n",
    "        examples.append({\"role\": \"user\", \"content\": user_content})\n",
    "        examples.append({\"role\": \"assistant\", \"content\": assistant_content})\n",
    "    \n",
    "    return examples\n",
    "\n",
    "# Helper function to process each category/platform with few-shot examples\n",
    "def process_category_platform(category, platform, html_content):\n",
    "    examples = generate_few_shot_examples(category, platform, html_data)\n",
    "    \n",
    "    if not examples:\n",
    "        return \"No valid few-shot examples for this category/platform.\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"qwen/qwen2.5-vl-72b-instruct:free\",  # Specify the model you want to use\n",
    "        messages=examples + [\n",
    "            {\"role\": \"user\", \"content\": f\"Extract the product attribute values from the HTML in a JSON format. Valid attributes are {', '.join(category_attributes[category])}:\\n{html_content}\\n\\nResponse:\"}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    if response.choices and response.choices[0].message and response.choices[0].message.content:\n",
    "        return response.choices[0].message.content\n",
    "    elif hasattr(response, \"error\"):\n",
    "        return f\"API Error: {response.error}\"\n",
    "    else:\n",
    "        return \"No content returned from the API.\"\n",
    "\n",
    "# Main loop for processing the test set HTML inputs\n",
    "for i, row in test_data.iterrows():\n",
    "    html_file_path = row[\"html\"]  # Get the path to the HTML file\n",
    "\n",
    "    # Read the HTML content from the file\n",
    "    try:\n",
    "        with open(html_file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            html_content = file.read()\n",
    "\n",
    "        # Process based on category and platform\n",
    "        if row[\"category\"] in category_attributes and row[\"platform\"] in platforms:\n",
    "            result = process_category_platform(row[\"category\"], row[\"platform\"], html_content)\n",
    "            test_data.at[i, 'qwen_fewshot'] = result  # Write result to 'qwen_fewshot' column\n",
    "            print(result)\n",
    "        else:\n",
    "            test_data.at[i, 'qwen_fewshot'] = \"No valid category.\"\n",
    "    except FileNotFoundError:\n",
    "        test_data.at[i, 'qwen_fewshot'] = f\"HTML file not found: {html_file_path}\"\n",
    "        print(f\"HTML file not found: {html_file_path}\")\n",
    "\n",
    "# Write the results back to the original dataframe\n",
    "html_data.update(test_data[['html', 'qwen_fewshot']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_data.to_json(\"html_data.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few-shot all training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "import json\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI(base_url=\"\", api_key=\"\")\n",
    "\n",
    "# Load the HTML data from the Excel file\n",
    "html_data = pd.read_excel(\"html_data.xlsx\")\n",
    "\n",
    "# Filter the test data from the dataset\n",
    "test_data = html_data[html_data['set'] == 'test']\n",
    "\n",
    "# Define category-specific attribute sets\n",
    "category_attributes = {\n",
    "    \"fashion\": \"Object, Brand, Color, Size, Material, Department, Style, Price\",\n",
    "    \"electronics\": \"Object, Brand, Color, Size, Material, Model, Power Mode, Price\",\n",
    "    \"beauty\": \"Object, Brand, Volume, Material, Skin/Hair Type, Benefits, Price\"\n",
    "}\n",
    "\n",
    "platforms = [\"amazon\", \"ebay\", \"temu\"]\n",
    "\n",
    "# Helper function to generate few-shot examples based on the \"train\" set data\n",
    "def generate_few_shot_examples(data):\n",
    "    examples_by_category = {category: [] for category in category_attributes.keys()}\n",
    "    \n",
    "    # Filter data based on category and platform\n",
    "    for category in category_attributes.keys():\n",
    "        for platform in platforms:\n",
    "            filtered_data = data[(data['category'] == category) & (data['platform'] == platform) & (data['set'] == 'train')]\n",
    "            \n",
    "            for _, row in filtered_data.iterrows():\n",
    "                html_file_path = row['html']  # Path to the HTML file\n",
    "                \n",
    "                # Read the HTML content from the file\n",
    "                try:\n",
    "                    with open(html_file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                        html_content = file.read()\n",
    "                except FileNotFoundError:\n",
    "                    print(f\"File not found: {html_file_path}\")\n",
    "                    html_content = \"\"\n",
    "                \n",
    "                reference_output = row['reference_output']  # Correct answer (reference output)\n",
    "                \n",
    "                # Construct the few-shot example\n",
    "                example = {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You are an algorithm that extracts product attributes from HTML in a structured format. Only extract the specified attributes and exclude unrelated information.\"\n",
    "                }\n",
    "                \n",
    "                user_content = f\"Extract product attributes from the HTML. Valid attributes are {', '.join(category_attributes.get(category, []))}. If an attribute is not present in the HTML, the value should be 'n/a'.\\n\\nHTML content:\\n{html_content}\\n\\nReference Output:\\n{reference_output}\"\n",
    "                assistant_content = reference_output  # The correct response to match the attributes\n",
    "                \n",
    "                examples_by_category[category].append({\"role\": \"user\", \"content\": user_content})\n",
    "                examples_by_category[category].append({\"role\": \"assistant\", \"content\": assistant_content})\n",
    "    \n",
    "    return examples_by_category\n",
    "\n",
    "# Generate few-shot examples for each category\n",
    "few_shot_examples_by_category = generate_few_shot_examples(html_data)\n",
    "\n",
    "# Helper function to process each test row with the appropriate few-shot examples for its category\n",
    "def process_with_category_examples(category, html_content):\n",
    "    if category not in few_shot_examples_by_category:\n",
    "        return \"No valid few-shot examples for this category.\"\n",
    "\n",
    "    examples = few_shot_examples_by_category[category]\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"mistralai/mistral-small-3.1-24b-instruct:free\",  # Specify the model you want to use\n",
    "        messages=examples + [\n",
    "            {\"role\": \"user\", \"content\": f\"Extract the product attribute values from the HTML in a JSON format. Valid attributes are {', '.join(category_attributes[category])}:\\n{html_content}\\n\\nResponse:\"}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    if response.choices and response.choices[0].message and response.choices[0].message.content:\n",
    "        return response.choices[0].message.content\n",
    "    elif hasattr(response, \"error\"):\n",
    "        return f\"API Error: {response.error}\"\n",
    "    else:\n",
    "        return \"No content returned from the API.\"\n",
    "\n",
    "# Main loop for processing the test set HTML inputs\n",
    "for i, row in test_data.iterrows():\n",
    "    html_file_path = row[\"html\"]  # Get the path to the HTML file\n",
    "\n",
    "    # Read the HTML content from the file\n",
    "    try:\n",
    "        with open(html_file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            html_content = file.read()\n",
    "\n",
    "        # Process using the few-shot examples for the correct category\n",
    "        category = row[\"category\"]\n",
    "        result = process_with_category_examples(category, html_content)\n",
    "        test_data.at[i, 'llama_fewshot'] = result  # Write result to 'llama_fewshot' column\n",
    "        print(result)\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        test_data.at[i, 'llama_fewshot'] = f\"HTML file not found: {html_file_path}\"\n",
    "        print(f\"HTML file not found: {html_file_path}\")\n",
    "\n",
    "# Write the results back to the original dataframe\n",
    "html_data.update(test_data[['html', 'llama_fewshot']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
